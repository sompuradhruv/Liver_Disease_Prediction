Deep learning and Machine Learning can be used to diagnose various diseases like liver diseases. India has more than a million people getting diagnosed with liver diseases each year hence it's essential to detect them early. These are caused due to consumption of alcohol, contaminated food, and obesity, thus we need a system that can predict the symptoms of liver diseases. We can predict these diseases using patient data and deep learning algorithms. The performance of this system can be measured in terms of accuracy, recall f-measure, etc. In this project, I have tried to use deep learning and data mining techniques to help this noble cause of detecting liver diseases at an early stage.  I have used three hybrid algorithms: CNN combined with LSTM(99.02%), CNN combined with GRU(98.38%), and CNN combined with RNN(99.48%).

We are going to use the following deep learning algorithms for our project and compare their accuracy â€“ 

**1.	 LSTM-CNN:**
There are several ways to enhance model performance, such as changing batch size and number of epochs, dataset curating, adjusting the ratio of the training, validation, and test datasets, changing loss functions and model architectures, and so on. In this project, we will improve model performance by changing the model architecture. More specifically, we will see if the CNN-LSTM model can predict liver disease cases better than the LSTM model.
The CNN layers that extract the feature from input data and LSTMs layers to provide sequence prediction.

**2.	CNN + GRU:**
To combine the advantages of the GRU module which can well process time se-quence data and the advantages of the CNN module which is ideal for handling high-dimensional data, the GRU-CNN hybrid neural networks was proposed
The proposed GRU-CNN hybrid neural network framework consists of GRU and CNN modules. The inputs are time series data collected from the energy sys-tem and information from the spatiotemporal matrix. The output is a prediction of future load values. As for the CNN module, it is good at processing two-dimensional data such as: B. Spatio-temporal matrices and images. The CNN en-gine uses local connections and shared weights to directly extract local features from spatio-temporal matrix data and obtain efficient representations through convolution and pooling layers. The structure of the CNN module contains two layers of convolutions and one flattening operation, and each layer of convolu-tions contains one convolution operation and one pooling operation. After the second pooling operation, the high-dimensional data is flattened to 1-dimensional data and the output of the CNN module is combined into a fully connected layer. On the other hand, the purpose of the GRU module is to grasp long-term dependencies, and the GRU module can learn useful information from historical data through memory cells over a long period of time, and unneeded information can be learned over a long period of time. be forgotten. Gate of Oblivion. The input to the GRU module is time series data. The GRU module con-tains many gate recursion units, and the outputs of all these gate recursion units are connected to fully connected layers. Finally, the load prediction result can be obtained by averaging over all neurons in the fully connected layer.

**3.	CNN + RNN:**
The proposed model makes use of the ability of the CNN to extract local features and of the LSTM to learn long-term dependencies. First, a CNN layer of Conv1D is used for processing the input vectors and extracting the local features that re-side at the text-level. The output of the CNN layer (i.e. the feature maps) are the input for the RNN layer of LSTM units/cells that follows. The RNN layer uses the local features extracted by the CNN and learns the long-term dependencies of the local features The proposed model makes use of the ability of the CNN to extract local features and of the LSTM to learn long-term dependencies. First, a CNN layer of Conv1D is used for processing the input vectors and extracting the local features that reside at the text-level. The output of the CNN layer (i.e. the feature maps) are the input for the RNN layer of LSTM units/cells that follows. The RNN layer uses the local features extracted by the CNN and learns the long-term de-pendencies of the local features


